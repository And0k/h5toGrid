[in]
path = d:\WorkData\BalticSea\171003_ANS36\navigation\bridge\??????.txt
#d:\workData\BalticSea\170614_ANS34\navigation\bridge\??????.txt
#d:\WorkData\BalticSea\170614_ANS34\navigation\bridge\*.txt
dt_from_utc_hours = 0

delimiter_chars = , ; not specify if need "None" useful for fixed length format
skiprows_integer = 1 ; skip header
#function cfg_input_cols_init depends from this:
; ����         �����       ������         �������        ����      ��������  ��������         �������
;16 08 04,   23 00 01,   5505.643066,N, 1907.243042,E, 281.90,    00.60,     230.33,         -98.27
header = date(text),Time(text),Lat,Lat_NS(text),Lon,Lon_WE(text),Course,Speed,Gyro,DepEcho
coldate_integer = 0
coltime_integer = 1
#cols_not_use_list= Lat_NS,Lon_WE
#10-03-2016 10:06:16.83 is two columns: DD-MM-Y and hh:mm:ss.ff
#DateStart_M8_D= np.datetime64(_txtD[0][6:10]+_txtD[0][2:6]+_txtD[0][0:2]) - np.datetime64('2009-01-01')
max_text_width = 12
b_raise_on_err = False   ;
keep_input_nans = True   ; data is mainly ok except multiple heders which are loaded as NaNs - not need interp
#comments= � ; first char of repeated header # must be in latin1 range
b_skip_if_up_to_date = True

[filter]
min_Lat = 0 ; -100
min_Lon = 0 ; -100   # 0 means get data only from Easten hemisphere
min_date = 01.01.2020 00:00:00  ; better to set because of existance of bad dates before this value
#min_date= 17.06.2017 21:50:00 ; UTC, not output data < min_date
#max_date= 31.12.2017 00:00:00 ; UTC, not output data > max_date

[out]
b_insert_separator = False ; insert NaNs between files
b_reuse_temporary_tables = False ; Warning! If True and b_skip_if_up_to_date= True then not replace temporary file with result before proc.
chunksize_percent_float = 5 ; this is big files, use smaller chanks to load them faster
b_remove_duplicates = True ; False. Set True if you see warnings about

[program]
log = log/csv2h5_supervisor.log ; log operations